#### 为什么要对数据进行降维？

&emsp; &emsp; 1. 降维可以缓解维度灾难问题。

&emsp; &emsp;2. 降维可以在压缩数据的同时让信息损失最小化。

&emsp; &emsp;3. 理解几百个维度的数据结构很困难，两三个维度的数据通过可视化更容易理解。

&emsp; &emsp;4，降低很多算法的开销，去除噪声，使得数据集更易用

#### 对于PCA（Principal Component Analysis，主成分分析）的理解:PCA通过线性变换将原始数据变换为一组各维度*线性无关*的表示，

可用于提取数据的主要特征分量，常用于高维数据降维。直白的来说，就是对一个样本矩阵:

&emsp;（1）换特征，找一组新的特征来重新表示

&emsp;（2）减少特征，新特征的数目要远小于原特征的数目

&emsp; 1、什么是主成分？

&emsp;矩阵的主成分是由其协方差矩阵的特征向量，按照对应的特征值大小排序得到的。

&emsp;最大的特征值就是第一主成分，第二大的特征值就是第二主成分，以此类推。

&emsp; 2、主成分分析方法为什么能够降维？

&emsp;  协方差（Covariance）是度量两个变量的变动的同步程度，也就是度量两个变量线性相关性程度。我们进行数据降维是为了降低数据的维度，同时保留含有信息量大的数据。

在给定的数据集中，其协方差矩阵可以衡量给定数据集各个维度之间的相关程度，那么我们希望数据集的协方差矩阵对角线元素尽量的大，非对角元素尽量的小，最好为0。

对于协方差矩阵的特征值和特征向量，可以这么理解，特征值是数据集变换后方差的大小，特征向量是是数据集进行变换后空间的坐标基底（也就是正交基）

#### PCA实现的流程

&emsp; 将数据转换成前N个主成分的伪代码大致如下:

&emsp; &emsp; 去除平均值

&emsp; &emsp; 计算数据集的协方差矩阵

&emsp; &emsp; 计算协方差矩阵的特征值和特征向量

&emsp; &emsp; 将特征值从大到小排序

&emsp; &emsp; 保留上面的前N个特征向量

&emsp; &emsp; 将数据转换到上述N个特征向量构建的新空间中

